\chapter{Introduction}\label{c:intro}

Nowadays, more than ever, due to society becoming more dependent on technology, the amount of data that is streamed over the internet is bigger than what it ever was. However, raw data just by itself is not valuable, so, in order for raw data to become relevant information, it is necessary to process it.

Recent technological developments in Internet of Things have led to an increased usage of data streaming processing. Namely, due to the fast data generation and to the increasing use of machine learning techniques, there is a rising need for real-time data analysis and the use of distributed stream processing applications.
In the past we witnessed people manually introducing data into a computer, something that is unrealistic for the reality society faces nowadays. In this day and age, computers feed data, at a very fast rate, into each other. Some sources even do it uninterruptedly, such as, wireless networks, sensor networks, telephone records, etc. \cite{dataprocessingbook} %(https://link.springer.com/chapter/10.1007\%2F3-540-73679-4_3)
As a result, a security problem may arise from it because this data has a significant probability of containing customer confidential secrets, which can range from the phone number to the current health status of an ill person. \cite{anonymizingstreamingdata, 7024651} % (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4497558) (https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7024651)

Thus, and knowing that businesses, especially startups, small and medium businesses, are increasingly opting for data and computation outsourcing to cloud computing, open channel transmission of sensitive data is limited because those services leave users vulnerable to attacks that may compromise the integrity and confidentiality of their sensitive information \cite{soteria, 6227695, IQBAL201698, 5655240}, thus, restricting its use.
Besides, with the rising number of regulations such as HIPAA and GDPR, users' sensitive data cannot be processed nor sent to untrusted third-party infrastructures without users’ consent and the adoption of strong security policies. \cite{usersdataarticle, dataprotection}

Taking this into account, anonymization and cryptographic techniques have been used to tackle those vulnerabilities. Still, these techniques may be reverted or they might have an uncontrolled computation and processing time increase. On the other hand, the emergence of TEEs (Trusted Execution Environments), such as Intel-SGX (Intel Software Guard Extensions) \cite{intelsgxexplained}, come as a potential solution to guarantee users’ data confidentiality. 

%Citing example: \cite{GRM97}

\section{Problem Statement}\label{s:problem}
In an ideal world, every computation should be done in a secure space that ensures strong security guarantees. With such conditions, data streaming would never lead to the exposure of users' confidential data. Nevertheless, it is known that most applications do not ensure such guarantees. 

The common data steaming processing workflow presents three main phases, namely: data input, data streaming and finally data processing. In the first phase, it is gathered the relevant data that one wants to outsource. After the raw data is collected, it then proceeds to be sent and as it reaches the destination, it starts to get processed to generate relevant information. However, during the data streaming and data processing phases, users’ data is susceptible to several attacks, ranging from external attacks (e.g., hackers) to internal attacks (e.g., malicious system administrators), respectively.

When the topic is security vulnerabilities, the first thing that pops into one's mind is data encryption. However, as important as data encryption is, most of the time it does not defeat those obstacles just by itself.

Adopting software-based cryptographic techniques (e.g., homomorphic encryption) aims to defeat these setbacks whilst offering privacy-preserving data streaming processing solutions. Nevertheless, such techniques limit the operations that can be carried over encrypted data and/or impose a significant performance toll that restricts their applicability to practical scenarios. \cite{soteria}

However, in order to overtake these challenges, a technology has emerged as a viable alternative for delivering a secure, integrity-protected processing environment in which data can be processed in its original form, that is, without being encrypted (e.g., plaintext), at an untrusted storage server.\cite{7345265} This solution is called Trusted Execution Environment (TEEs) (e.g., Intel SGX \cite{sgxdocs, intelsgxexplained}, AMD-PSP, IBM Secure Execution).

Be that as it may, choosing which data and computations have to be done at the secure enclave is not a trifling task. Ideally, all operations should be done inside a secure space in the interesting of ensuring strong security guarantees. Nonetheless, the performance overhead of the solution increases accordingly to the amount of operations and data that are at the enclave. Actually, there is a way to even the security guarantees and performance scales, though, the calculation of such balance depends deeply on one's definition of which data is sensitive and which computations will not divulge confidential information.

Furthermore, in the data processing phase, and taking into consideration that big data is ubiquitous nowadays, on the chance of having to treat big loads of data, it is necessary to be especially mindful when choosing the appropriate software framework. MapReduce and Spark are two of the most popular open source frameworks for processing massive amounts of data on ordinary hardware. These systems offer simple APIs that conceal the sophistication of simultaneous job execution and fault tolerance from the user. \cite{mapreducevsspark}

% NESTE PAPER DIZ QUE O SPARK É MELHOR

\section{Objectives and Contributions}
This master thesis aims to develop a secure streaming solution based on the combined usage of cryptographic techniques and trusted hardware technologies. Also, the proposed system will be based on the widely used distributed computation platform, Apache Spark. The solution must offer end-to-end user security guarantees capable of meeting the needs of current data protection regulations (e.g., GDPR). In more detail, it is expected to be created a system where the user connects with an untrusted entity, that does not offer data privacy guarantees, but implements Intel’s SGX technology. The latter will provide a trusted execution environment (enclave) where data computation can be done in plaintext but without disclosing any sensitive information to both external (e.g., hackers) and internal attackers (e.g., malicious system administrators). However, as the amount of operations and data increases at the enclave so does the performance overhead of the solution. Therefore, this thesis will require understanding what computation and data should be moved to a secure enclave, as well as the performance and security implications of the solution. To do so, the proposed design requires to be implemented as a prototype and evaluated with realistic workloads. 

\section{Document Structure}
The current pre-dissertation document is divided into 3 different chapters, namely: State of the Art (\ref{c:sota}), Current work (\ref{c:currWork}) and Conclusion and Future work (\ref{c:conc}). COMPLETE WHEN READY!!!